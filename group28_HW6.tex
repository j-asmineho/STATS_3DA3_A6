% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  11pt,
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{setspace}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin = 1in]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\usepackage{amsmath}
\usepackage{bbm}
\usepackage{array}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{float}
\usepackage{apacite}
\usepackage{natbib}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={STATS 3DA3},
  pdfauthor={Ashley Chen, Jasmine Ho, JC Abanto},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{STATS 3DA3}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Homework Assignment 6}
\author{Ashley Chen, Jasmine Ho, JC Abanto}
\date{2025-04-16}

\begin{document}
\maketitle


\setstretch{1.5}
\newpage

\section{Question}\label{question}

\subsubsection{1)}\label{section}

Our target variable measure the severity of heart disease which can be
defined as binary classification problem. Our goal would then to be able
to predict the probability of heart disease. This means we can carry out
a logistic regression and a random forest classifier to predict the
presence and absence of heart disease.

\subsubsection{2)}\label{section-1}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ ucimlrepo }\ImportTok{import}\NormalTok{ fetch\_ucirepo}
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
  
\NormalTok{heart\_disease }\OperatorTok{=}\NormalTok{ fetch\_ucirepo(}\BuiltInTok{id}\OperatorTok{=}\DecValTok{45}\NormalTok{) }
 
\NormalTok{X }\OperatorTok{=}\NormalTok{ heart\_disease.data.features }
\NormalTok{y }\OperatorTok{=}\NormalTok{ heart\_disease.data.targets }

\NormalTok{scaler }\OperatorTok{=}\NormalTok{ StandardScaler()}
\NormalTok{X\_train\_scaled }\OperatorTok{=}\NormalTok{ scaler.fit\_transform(X)}
\end{Highlighting}
\end{Shaded}

\subsubsection{3)}\label{section-2}

We have 13 features and 1 target variable. Starting with our features,
we have age (age in years), sex (1 = male; 0 = female), cp (1: typical
angina, 2: atypical angina, 3: non-anginal pain, 4: asymptomatic),
trestbps (resting blood pressure in mm Hg on admission to the hospital),
chol (serum cholestoral in mg/dl), fbs (fasting blood sugar
\textgreater{} 120 mg/dl where 1 = true; 0 = false), restecg (resting
electrocardiographic results), exang (exercise induced angina), oldpeak
(ST depression induced by exercise relative to rest), slope (1 =
upsloping, 2 = flat, 3 = downsloping), ca (number of major vessels
colored by floursopy), thal (3 = normal; 6 = fixed defect; 7 =
reversable defect). Finally our target variable, `num', is the diagnosis
of heart disease.

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Observations in X: }\SpecialCharTok{\{}\BuiltInTok{len}\NormalTok{(X)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Summary of X:}\CharTok{\textbackslash{}n}\SpecialCharTok{\{}\NormalTok{X}\SpecialCharTok{.}\NormalTok{describe()}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Summary of y:}\CharTok{\textbackslash{}n}\SpecialCharTok{\{}\NormalTok{y}\SpecialCharTok{.}\NormalTok{describe()}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We find that the average age of patients is 54.4 years old, with a
standard deviation of 9.1 years.

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Data Types of X: }\CharTok{\textbackslash{}n}\SpecialCharTok{\{}\NormalTok{X}\SpecialCharTok{.}\NormalTok{dtypes}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\CharTok{\textbackslash{}n}\SpecialStringTok{Data Types of y: }\CharTok{\textbackslash{}n}\SpecialCharTok{\{}\NormalTok{y}\SpecialCharTok{.}\NormalTok{dtypes}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

All of our data types in X are numerical but some representing
categorical variables.

\subsubsection{4)}\label{section-3}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"y before transformation: }\SpecialCharTok{\{}\NormalTok{y[}\StringTok{\textquotesingle{}num\textquotesingle{}}\NormalTok{]}\SpecialCharTok{.}\NormalTok{value\_counts()}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\NormalTok{y[}\StringTok{\textquotesingle{}num\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ y[}\StringTok{\textquotesingle{}num\textquotesingle{}}\NormalTok{].}\BuiltInTok{apply}\NormalTok{(}\KeywordTok{lambda}\NormalTok{ x: }\DecValTok{1} \ControlFlowTok{if}\NormalTok{ x }\OperatorTok{\textgreater{}} \DecValTok{0} \ControlFlowTok{else} \DecValTok{0}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"y before transformation: }\SpecialCharTok{\{}\NormalTok{y[}\StringTok{\textquotesingle{}num\textquotesingle{}}\NormalTok{]}\SpecialCharTok{.}\NormalTok{value\_counts()}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{5)}\label{section-4}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ seaborn }\ImportTok{as}\NormalTok{ sns}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}

\NormalTok{corr\_matrix }\OperatorTok{=}\NormalTok{ X.corr()}

\NormalTok{plt.figure(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{6}\NormalTok{))}
\NormalTok{sns.heatmap(corr\_matrix, annot}\OperatorTok{=}\VariableTok{True}\NormalTok{, cmap}\OperatorTok{=}\StringTok{\textquotesingle{}coolwarm\textquotesingle{}}\NormalTok{, fmt}\OperatorTok{=}\StringTok{".2f"}\NormalTok{, linewidths}\OperatorTok{=}\FloatTok{0.5}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{"Correlation Heatmap"}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

From this correlation matrix, we can conclude that thalach (max heart
rate) has a strong negative correlation (-0.39) with age and oldpeak. We
can assume that younger individuals tend to have a higher heart rate,
while those with more severe heart disease (higher oldpeak) have lower
thalach. We also found that ca (number of major vessels) has a strong
positive correlation (0.36) with age. We can say that older individuals
are more likely to have more blocked vessels.

\subsubsection{6)}\label{section-5}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OperatorTok{=}\NormalTok{ X.dropna()}
\NormalTok{y }\OperatorTok{=}\NormalTok{ y.loc[X.index]}

\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Length of X after transformations: }\SpecialCharTok{\{}\BuiltInTok{len}\NormalTok{(X)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Length of y after transformations: }\SpecialCharTok{\{}\BuiltInTok{len}\NormalTok{(y)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{7)}\label{section-6}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ silhouette\_samples, silhouette\_score}
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
\ImportTok{from}\NormalTok{ sklearn.decomposition }\ImportTok{import}\NormalTok{ PCA}
\ImportTok{from}\NormalTok{ sklearn.cluster }\ImportTok{import}\NormalTok{ KMeans}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}

\CommentTok{\# Assume X is your original DataFrame}
\NormalTok{categorical\_columns }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}sex\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}cp\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}fbs\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}restecg\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}exang\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}slope\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}thal\textquotesingle{}}\NormalTok{]}
\NormalTok{X\_cleaned }\OperatorTok{=}\NormalTok{ X.drop(columns}\OperatorTok{=}\NormalTok{categorical\_columns)}

\CommentTok{\# Scaling}
\NormalTok{scaler }\OperatorTok{=}\NormalTok{ StandardScaler()}
\NormalTok{X\_scaled }\OperatorTok{=}\NormalTok{ scaler.fit\_transform(X\_cleaned)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{k\_range }\OperatorTok{=} \BuiltInTok{range}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{10}\NormalTok{)}
\NormalTok{silhouette\_scores }\OperatorTok{=}\NormalTok{ []}

\ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in}\NormalTok{ k\_range:}
\NormalTok{    kmeans }\OperatorTok{=}\NormalTok{ KMeans(n\_clusters }\OperatorTok{=}\NormalTok{ k, n\_init }\OperatorTok{=} \DecValTok{20}\NormalTok{, random\_state }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\NormalTok{    cluster\_labels }\OperatorTok{=}\NormalTok{ kmeans.fit\_predict(X\_scaled)}
\NormalTok{    silhouette\_avg }\OperatorTok{=}\NormalTok{ silhouette\_score(X\_scaled, cluster\_labels)}
\NormalTok{    silhouette\_scores.append(silhouette\_avg)}

\NormalTok{plt.figure(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{9}\NormalTok{, }\DecValTok{5}\NormalTok{))}
\NormalTok{plt.plot(k\_range, silhouette\_scores, marker}\OperatorTok{=}\StringTok{\textquotesingle{}o\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{"Silhouette Score"}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{"Number of Clusters (k)"}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{"k Values Silhouette Score"}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pca }\OperatorTok{=}\NormalTok{ PCA(n\_components}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{X\_pca }\OperatorTok{=}\NormalTok{ pca.fit\_transform(X\_scaled)}

\NormalTok{kmeans }\OperatorTok{=}\NormalTok{ KMeans(n\_clusters}\OperatorTok{=}\DecValTok{2}\NormalTok{, random\_state}\OperatorTok{=}\DecValTok{42}\NormalTok{)}
\NormalTok{clusters }\OperatorTok{=}\NormalTok{ kmeans.fit\_predict(X\_scaled)}

\NormalTok{plt.scatter(X\_pca[:, }\DecValTok{0}\NormalTok{], X\_pca[:, }\DecValTok{1}\NormalTok{], c}\OperatorTok{=}\NormalTok{clusters, cmap}\OperatorTok{=}\StringTok{\textquotesingle{}viridis\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{"K{-}Means Clustering (k=2)"}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{"PC1"}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{"PC2"}\NormalTok{)}
\NormalTok{plt.colorbar(label}\OperatorTok{=}\StringTok{"Cluster"}\NormalTok{)}
\NormalTok{plt.show()}

\NormalTok{X\_scaled\_df }\OperatorTok{=}\NormalTok{ pd.DataFrame(X\_scaled, columns}\OperatorTok{=}\NormalTok{X\_cleaned.columns)}
\NormalTok{X\_scaled\_df[}\StringTok{\textquotesingle{}cluster\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ clusters}
\end{Highlighting}
\end{Shaded}

\subsubsection{8)}\label{section-7}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ train\_test\_split}

\NormalTok{X\_train, X\_test, y\_train, y\_test }\OperatorTok{=}\NormalTok{ train\_test\_split(X, y, test\_size}\OperatorTok{=}\FloatTok{0.30}\NormalTok{, random\_state}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{9)}\label{section-8}

We are going to use logistic regression and random forest. Logistic
regression is suitable for this assignment because it predicts a binary
outcome, in which case, the target variable is 0 or 1. Random forest is
also a good classifier to use because it has high predictive accuracy
and does not depend on linear relationships, which is good for this
dataset as there are both numerical and categorical variables.

\subsubsection{10)}\label{section-9}

We are going to use accuracy and F1 scores to compare the classifier
performance between logistic regression and random forest. We can create
the confusion matrix from the predictions to calculate the accuracy and
F1 scores. Accuracy scores are calculated by the number of correct
predictions over the total number of predictions.

\begin{align*}
\text{Accuracy} &= \frac{TP + TN}{TP + TN + FP + FN} \\
\text{Where:} \\
TP &= \text{True Positives} \\
TN &= \text{True Negatives} \\
FP &= \text{False Positives} \\
FN &= \text{False Negatives}
\end{align*}

To obtain the F1 score, we will need to use precision and recall that
are derived from the confusion matrix. Once we calculate that, the F1
score can be calculated by:

\begin{align*}
\text{Precision} &= \frac{TP}{TP + FP} \\
\text{Recall} &= \frac{TP}{TP + FN} \\
F_1 &= \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
\end{align*}

Using these metrics, we can compare the overall accuracy and balance
between the two classifiers to determine which classifier most optimal
for predicting heart disease.

\subsubsection{11)}\label{section-10}

\begin{Shaded}
\begin{Highlighting}[]

\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ train\_test\_split, GridSearchCV}
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ accuracy\_score, confusion\_matrix, classification\_report}

\NormalTok{scaler }\OperatorTok{=}\NormalTok{ StandardScaler()}
\NormalTok{X\_train\_scaled }\OperatorTok{=}\NormalTok{ scaler.fit\_transform(X\_train)}
\NormalTok{X\_test\_scaled }\OperatorTok{=}\NormalTok{ scaler.transform(X\_test)}

\NormalTok{log\_reg }\OperatorTok{=}\NormalTok{ LogisticRegression(solver}\OperatorTok{=}\StringTok{\textquotesingle{}liblinear\textquotesingle{}}\NormalTok{, max\_iter}\OperatorTok{=}\DecValTok{1000}\NormalTok{, random\_state}\OperatorTok{=}\DecValTok{42}\NormalTok{)}

\NormalTok{param\_grid }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{\textquotesingle{}penalty\textquotesingle{}}\NormalTok{: [}\StringTok{\textquotesingle{}l1\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}l2\textquotesingle{}}\NormalTok{],}
    \StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{: [}\FloatTok{0.001}\NormalTok{, }\FloatTok{0.01}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{1000}\NormalTok{] }\CommentTok{\# test this out to see if accuracy improves}
\NormalTok{\}}

\NormalTok{grid\_search }\OperatorTok{=}\NormalTok{ GridSearchCV(estimator}\OperatorTok{=}\NormalTok{log\_reg, param\_grid}\OperatorTok{=}\NormalTok{param\_grid, cv}\OperatorTok{=}\DecValTok{5}\NormalTok{, scoring}\OperatorTok{=}\StringTok{\textquotesingle{}accuracy\textquotesingle{}}\NormalTok{, n\_jobs}\OperatorTok{={-}}\DecValTok{1}\NormalTok{, verbose}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
\NormalTok{grid\_search.fit(X\_train\_scaled, y\_train)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Best parameters found: "}\NormalTok{, grid\_search.best\_params\_)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Best cross{-}validation accuracy: }\SpecialCharTok{\{:.4f\}}\StringTok{"}\NormalTok{.}\BuiltInTok{format}\NormalTok{(grid\_search.best\_score\_))}

\NormalTok{best\_log\_reg }\OperatorTok{=}\NormalTok{ grid\_search.best\_estimator\_}
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ best\_log\_reg.predict(X\_test\_scaled)}
\NormalTok{y\_pred2 }\OperatorTok{=}\NormalTok{ best\_log\_reg.predict(X\_train\_scaled)}

\NormalTok{accuracy }\OperatorTok{=}\NormalTok{ accuracy\_score(y\_test, y\_pred)}
\NormalTok{train\_accuracy }\OperatorTok{=}\NormalTok{ accuracy\_score(y\_train, y\_pred2)}
\NormalTok{cm }\OperatorTok{=}\NormalTok{ confusion\_matrix(y\_test, y\_pred)}
\NormalTok{report }\OperatorTok{=}\NormalTok{ classification\_report(y\_test, y\_pred, target\_names}\OperatorTok{=}\NormalTok{[}\StringTok{\textquotesingle{}No Heart Disease\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Heart Disease\textquotesingle{}}\NormalTok{])}

\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Test set accuracy: }\SpecialCharTok{\{}\NormalTok{accuracy}\SpecialCharTok{:.4f\}}\SpecialStringTok{"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Train set accuracy: }\SpecialCharTok{\{}\NormalTok{train\_accuracy}\SpecialCharTok{:.4f\}}\SpecialStringTok{"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Confusion Matrix:"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(cm)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Classification Report:"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(report)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ train\_test\_split, GridSearchCV}
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
\ImportTok{from}\NormalTok{ sklearn.ensemble }\ImportTok{import}\NormalTok{ RandomForestClassifier, GradientBoostingClassifier}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ accuracy\_score, confusion\_matrix, classification\_report}


\NormalTok{rf\_clf }\OperatorTok{=}\NormalTok{ RandomForestClassifier(random\_state}\OperatorTok{=}\DecValTok{42}\NormalTok{)}
\NormalTok{rf\_param\_grid }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{\textquotesingle{}n\_estimators\textquotesingle{}}\NormalTok{: [}\DecValTok{100}\NormalTok{, }\DecValTok{200}\NormalTok{, }\DecValTok{300}\NormalTok{],}
    \StringTok{\textquotesingle{}max\_depth\textquotesingle{}}\NormalTok{: [}\VariableTok{None}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{30}\NormalTok{],}
    \StringTok{\textquotesingle{}min\_samples\_split\textquotesingle{}}\NormalTok{: [}\DecValTok{2}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{],}
    \StringTok{\textquotesingle{}max\_features\textquotesingle{}}\NormalTok{: [}\StringTok{\textquotesingle{}sqrt\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}log2\textquotesingle{}}\NormalTok{, }\VariableTok{None}\NormalTok{],}
    \StringTok{\textquotesingle{}criterion\textquotesingle{}}\NormalTok{: [}\StringTok{\textquotesingle{}gini\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}entropy\textquotesingle{}}\NormalTok{]}
\NormalTok{\}}

\NormalTok{rf\_grid\_search }\OperatorTok{=}\NormalTok{ GridSearchCV(estimator}\OperatorTok{=}\NormalTok{rf\_clf, param\_grid}\OperatorTok{=}\NormalTok{rf\_param\_grid, cv}\OperatorTok{=}\DecValTok{5}\NormalTok{, scoring}\OperatorTok{=}\StringTok{\textquotesingle{}accuracy\textquotesingle{}}\NormalTok{, n\_jobs}\OperatorTok{={-}}\DecValTok{1}\NormalTok{, verbose}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
\NormalTok{rf\_grid\_search.fit(X\_train\_scaled, y\_train)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Random Forest Best Parameters:"}\NormalTok{, rf\_grid\_search.best\_params\_)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Random Forest Best Cross{-}Validation Accuracy:"}\NormalTok{, rf\_grid\_search.best\_score\_)}

\NormalTok{best\_rf\_clf }\OperatorTok{=}\NormalTok{ rf\_grid\_search.best\_estimator\_}
\NormalTok{rf\_y\_pred }\OperatorTok{=}\NormalTok{ best\_rf\_clf.predict(X\_test\_scaled)}

\NormalTok{rf\_accuracy }\OperatorTok{=}\NormalTok{ accuracy\_score(y\_test, rf\_y\_pred)}
\NormalTok{rf\_cm }\OperatorTok{=}\NormalTok{ confusion\_matrix(y\_test, rf\_y\_pred)}
\NormalTok{rf\_report }\OperatorTok{=}\NormalTok{ classification\_report(y\_test, rf\_y\_pred, target\_names}\OperatorTok{=}\NormalTok{[}\SpecialStringTok{f\textquotesingle{}Class }\SpecialCharTok{\{}\NormalTok{i}\SpecialCharTok{\}}\SpecialStringTok{\textquotesingle{}} \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in}\NormalTok{ np.unique(y)])}

\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Random Forest Test Accuracy: }\SpecialCharTok{\{}\NormalTok{rf\_accuracy}\SpecialCharTok{:.4f\}}\SpecialStringTok{"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Random Forest Confusion Matrix:"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(rf\_cm)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Random Forest Classification Report:"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(rf\_report)}
\end{Highlighting}
\end{Shaded}

\newpage

\subsubsection{References}\label{references}

Stack Overflow. (2014, February 16). Fine-tuning parameters in logistic
regression. Stack Overflow.
https://stackoverflow.com/questions/21816346/fine-tuning-parameters-in-logistic-regression

Stack Overflow. (2016, July 17). Random Forest Hyperparameter Tuning -
scikit-learn using GridSearchCV. Stack Overflow.
https://stackoverflow.com/questions/35164310/random-forest-hyperparameter-tuning-scikit-learn-using-gridsearchcv




\end{document}
